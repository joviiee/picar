{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from numba import cuda\n",
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import itertools\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,         # Rotate image up to 15 degrees\n",
    "    width_shift_range=0.1,     # Shift image horizontally by 10% of width\n",
    "    height_shift_range=0.1,    # Shift image vertically by 10% of height\n",
    "    zoom_range=0.2,            # Zoom in or out by 20%\n",
    "    horizontal_flip=True,      # Flip the image horizontally\n",
    "    rescale=1./255             # Normalize pixel values between 0 and 1\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\"trafficdata_new/train\",\n",
    "                                         target_size=(256, 256),\n",
    "                                         batch_size = 32,\n",
    "                                        class_mode='categorical')\n",
    "test_gen = valid_datagen.flow_from_directory(\"trafficdata_new/valid\",\n",
    "                                        target_size=(256, 256),\n",
    "                                       class_mode='categorical',\n",
    "                                       batch_size = 32,\n",
    "                                       shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Layer, GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Multiply, Conv2D, Concatenate\n",
    "\n",
    "# Channel Attention Module\n",
    "class ChannelAttention(keras.layers.Layer):\n",
    "    def __init__(self, channels, reduction=16, **kwargs):\n",
    "        super(ChannelAttention, self).__init__(**kwargs)\n",
    "        self.channels = channels\n",
    "        self.reduction = reduction\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.max_pool = GlobalMaxPooling2D()\n",
    "        self.fc1 = Dense(channels // reduction, activation=\"relu\", use_bias=False)\n",
    "        self.fc2 = Dense(channels, activation=\"sigmoid\", use_bias=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_out = self.fc2(self.fc1(self.avg_pool(inputs)))\n",
    "        max_out = self.fc2(self.fc1(self.max_pool(inputs)))\n",
    "        out = avg_out + max_out\n",
    "        return Multiply()([inputs, out])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ChannelAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"channels\": self.channels,\n",
    "            \"reduction\": self.reduction\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Spatial Attention Module\n",
    "class SpatialAttention(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpatialAttention, self).__init__(**kwargs)\n",
    "        self.conv = Conv2D(1, kernel_size=7, strides=1, padding=\"same\", activation=\"sigmoid\", use_bias=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_out = keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=-1, keepdims=True))(inputs)\n",
    "        max_out = keras.layers.Lambda(lambda x: keras.backend.max(x, axis=-1, keepdims=True))(inputs)\n",
    "        concat = Concatenate(axis=-1)([avg_out, max_out])\n",
    "        attention = self.conv(concat)\n",
    "        return Multiply()([inputs, attention])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SpatialAttention, self).get_config()\n",
    "        return config\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN Model with Attention\n",
    "model = keras.Sequential()\n",
    "\n",
    "# CNN Layers with Attention\n",
    "model.add(keras.layers.Conv2D(16, (5, 5), activation=\"relu\", padding=\"same\", input_shape=(256, 256, 3)))\n",
    "model.add(ChannelAttention(16))\n",
    "model.add(SpatialAttention())\n",
    "model.add(keras.layers.Conv2D(16, (5, 5), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(ChannelAttention(32))\n",
    "model.add(SpatialAttention())\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(ChannelAttention(64))\n",
    "model.add(SpatialAttention())\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(ChannelAttention(128))\n",
    "model.add(SpatialAttention())\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(ChannelAttention(256))\n",
    "model.add(SpatialAttention())\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(ChannelAttention(512))\n",
    "model.add(SpatialAttention())\n",
    "model.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Flatten and Reshape for LSTM\n",
    "model.add(keras.layers.Flatten())\n",
    "# model.add(keras.layers.Reshape((32, -1)))  # Reshape to (timesteps, features) for LSTM\n",
    "\n",
    "# # LSTM Layers\n",
    "# model.add(keras.layers.LSTM(128, return_sequences=True,dropout=0.1)) \n",
    "# model.add(keras.layers.LSTM(64,dropout=0.1))\n",
    "\n",
    "# Fully Connected Layers\n",
    "# model.add(keras.layers.Dense(480, activation=\"relu\"))\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(160, activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(6, activation=\"softmax\"))\n",
    "\n",
    "# Define Cosine Decay learning rate schedule\n",
    "initial_learning_rate = 0.0005  # Starting LR\n",
    "first_decay_steps = 230  # Number of training steps before LR reaches minimum\n",
    "t_mul = 2\n",
    "m_mul = 0.5\n",
    "alpha = 0.3 # Minimum LR factor (final LR will be initial_lr * alpha)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    first_decay_steps=first_decay_steps,\n",
    "    t_mul = t_mul,\n",
    "    m_mul = m_mul,\n",
    "    alpha=alpha,\n",
    ")\n",
    "\n",
    "# Compile the Model\n",
    "opt = keras.optimizers.AdamW(learning_rate=0.0003)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"tflite_saves/final_model_gmpool.keras\",  \n",
    "    monitor=\"val_accuracy\",      \n",
    "    save_best_only=True,\n",
    "    mode=\"max\",               \n",
    "    verbose=1                 \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 100\n",
    "history = model.fit(train_gen,\n",
    "          validation_data=test_gen,\n",
    "          epochs = ep,\n",
    "          callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Train and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(history.history['loss'],label=\"Train Loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Train and Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(history.history['accuracy'], label=\"Train Accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "custom_objects = {\n",
    "    \"ChannelAttention\": ChannelAttention,\n",
    "    \"SpatialAttention\": SpatialAttention\n",
    "}\n",
    "\n",
    "model = load_model(\"tflite_saves/final_model_gmpool.keras\",custom_objects = custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "labels = []\n",
    "predictions = []\n",
    "for x,y in test_gen:\n",
    "    labels.append(tf.argmax(y,1).numpy())\n",
    "    predictions.append(tf.argmax(model(x),1).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(itertools.chain.from_iterable(predictions))\n",
    "labels = list(itertools.chain.from_iterable(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Accuracy  : {:.2f} %\".format(history.history['accuracy'][-1]*100))\n",
    "print(\"Test Accuracy   : {:.2f} %\".format(accuracy_score(labels[:9912], predictions) * 100))\n",
    "print(\"Precision Score : {:.2f} %\".format(precision_score(labels[:9912], predictions, average='micro') * 100))\n",
    "print(\"Recall Score    : {:.2f} %\".format(recall_score(labels[:9912], predictions, average='micro') * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20,5))\n",
    "cm = confusion_matrix(labels[:9912], predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=list(range(1,7)))\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "disp.plot(ax=ax,colorbar= False,cmap = 'YlGnBu')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "print(classification_report(labels[:9912], predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "valid_gen = valid_datagen.flow_from_directory(\n",
    "    \"trafficdata_new/valid\",  # Path to your validation data\n",
    "    target_size=(256, 256),   # Resize images to match model input size\n",
    "    batch_size=32,            # Batch size\n",
    "    class_mode='categorical', # For classification tasks\n",
    "    shuffle=False             # Do not shuffle the data\n",
    ")\n",
    "def representative_dataset():\n",
    "    num_samples = 100  # Number of samples for the representative dataset\n",
    "    for i, (images, _) in enumerate(valid_gen):\n",
    "        for image in images:\n",
    "            yield [image[np.newaxis, ...]]  # Add batch dimension\n",
    "        if (i + 1) * valid_gen.batch_size >= num_samples:\n",
    "            break\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(\"96_model.keras\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  \n",
    "converter.inference_output_type = tf.int8  \n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('tflite_saves/model_full_quantised.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
